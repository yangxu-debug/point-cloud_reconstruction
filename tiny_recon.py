import numpy as np
import cv2
import pandas as pd
import open3d as o3d
import open3d.core as o3c
import os
import time

def save_colmap_compatible_ply(pcd, filename):
    """å°† tensor ç‚¹äº‘ä¿å­˜ä¸º COLMAP å…¼å®¹çš„ ASCII PLY"""
    pcd_legacy = pcd.to_legacy()
    points = np.asarray(pcd_legacy.points)
    colors = np.asarray(pcd_legacy.colors)
    colors_uchar = np.clip(colors * 255, 0, 255).astype(np.ubyte)
    assert points.shape[1] == 3 and colors.shape[1] == 3, "Invalid point or color shape"
    with open(filename, 'w') as f:
        f.write("ply\n")
        f.write("format ascii 1.0\n")
        f.write(f"element vertex {len(points)}\n")
        f.write("property float x\n")
        f.write("property float y\n")
        f.write("property float z\n")
        f.write("property uchar red\n")
        f.write("property uchar green\n")
        f.write("property uchar blue\n")
        f.write("end_header\n")
        for pt, col in zip(points, colors_uchar):
            f.write(f"{pt[0]} {pt[1]} {pt[2]} {col[0]} {col[1]} {col[2]}\n")
    print(f"COLMAP-compatible PLY saved to {filename}")

def read_camera_matrix(camera_matrix_path, target_size=(256, 192), original_size=(1920, 1440)):
    """è¯»å–å¹¶ç¼©æ”¾ç›¸æœºå†…å‚"""
    matrix = pd.read_csv(camera_matrix_path, header=None).values
    assert matrix.shape == (3, 3), "Camera matrix must be 3x3"
    fx, fy = matrix[0, 0], matrix[1, 1]
    cx, cy = matrix[0, 2], matrix[1, 2]
    orig_w, orig_h = original_size
    target_w, target_h = target_size
    fx_new = fx * target_w / orig_w
    fy_new = fy * target_h / orig_h
    cx_new = cx * target_w / orig_w
    cy_new = cy * target_h / orig_h
    return o3d.camera.PinholeCameraIntrinsic(
        width=target_w,
        height=target_h,
        fx=fx_new,
        fy=fy_new,
        cx=cx_new,
        cy=cy_new
    )

def quaternion_to_rotation_matrix(q):
    """å››å…ƒæ•°è½¬æ—‹è½¬çŸ©é˜µ"""
    w, x, y, z = q[3], q[0], q[1], q[2]
    R = np.array([
        [1 - 2*y*y - 2*z*z, 2*x*y - 2*w*z,     2*x*z + 2*w*y],
        [2*x*y + 2*w*z,     1 - 2*x*x - 2*z*z, 2*y*z - 2*w*x],
        [2*x*z - 2*w*y,     2*y*z + 2*w*x,     1 - 2*x*x - 2*y*y]
    ])
    return R

def read_odometry_csv(file_path):
    """è¯»å–ä½å§¿æ•°æ®"""
    df = pd.read_csv(file_path)
    odometry_data = {}
    for _, row in df.iterrows():
        frame = int(row[' frame'])
        odometry_data[frame] = {
            'timestamp': row['timestamp'],
            'position': np.array([row[' x'], row[' y'], row[' z']]),
            'quaternion': np.array([row[' qx'], row[' qy'], row[' qz'], row[' qw']])
        }
    return odometry_data

class RGBVideoLoader:
    """é«˜æ•ˆåŠ è½½ RGB è§†é¢‘å¸§"""
    def __init__(self, video_path, target_size=(256, 192)):
        self.video_path = video_path
        self.target_size = target_size
        self.cap = cv2.VideoCapture(video_path)
        if not self.cap.isOpened():
            raise IOError(f"Cannot open video: {video_path}")
        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self._current_frame_id = -1
        self._current_frame = None

    def get_frame(self, frame_idx):
        if frame_idx == self._current_frame_id:
            return self._current_frame
        if frame_idx < 0 or frame_idx >= self.frame_count:
            return None
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = self.cap.read()
        if not ret:
            return None
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_resized = cv2.resize(frame_rgb, self.target_size, interpolation=cv2.INTER_AREA)
        self._current_frame_id = frame_idx
        self._current_frame = frame_resized
        return frame_resized

    def release(self):
        if self.cap.isOpened():
            self.cap.release()

def get_depth_image(depth_path):
    """åŠ è½½æ·±åº¦å›¾ï¼ˆå•ä½ï¼šç±³ï¼‰"""
    if not os.path.exists(depth_path):
        return None
    try:
        img = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)
        return img / 1000.0  # å‡è®¾å•ä½æ˜¯æ¯«ç±³ â†’ è½¬ä¸ºç±³
    except Exception as e:
        print(f"Error loading depth image {depth_path}: {e}")
        return None

def depth_to_point_cloud(depth_image, intrinsic):
    """æ·±åº¦å›¾è½¬ç‚¹äº‘ï¼ˆä»…æ·±åº¦æœ‰æ•ˆèŒƒå›´ç­›é€‰ï¼‰"""
    h, w = depth_image.shape
    K = intrinsic.intrinsic_matrix
    fx, fy, cx, cy = K[0,0], K[1,1], K[0,2], K[1,2]
    u, v = np.meshgrid(np.arange(w), np.arange(h))
    z = depth_image
    x = (u - cx) * z / fx
    y = (v - cy) * z / fy
    points = np.stack((x, y, z), axis=-1).reshape(-1, 3)
    valid_mask = (z > 0.1) & (z < 10.0)
    valid_mask = valid_mask.ravel()
    return points[valid_mask], valid_mask

def color_point_cloud(rgb_frame, valid_mask):
    """æå–å¯¹åº”é¢œè‰²"""
    h, w, _ = rgb_frame.shape
    u, v = np.meshgrid(np.arange(w), np.arange(h))
    u = u.ravel()[valid_mask]
    v = v.ravel()[valid_mask]
    colors = rgb_frame[v, u] / 255.0
    return colors

def create_camera_frustum(R, t, intrinsic, scale=0.1, color=[1, 0.5, 0]):
    """
    åˆ›å»ºä¸€ä¸ªç›¸æœºè§†é”¥ä½“ï¼ˆé‡‘å­—å¡”å½¢çŠ¶ï¼‰
    - R: æ—‹è½¬çŸ©é˜µ (3,3)
    - t: å¹³ç§»å‘é‡ (3,)
    - intrinsic: PinholeCameraIntrinsic
    - scale: æ§åˆ¶è§†é”¥ä½“å¤§å°ï¼ˆè¡¨ç¤ºè§†é”¥ä½“æ·±åº¦ï¼‰
    - color: é¢œè‰²ï¼ˆé»˜è®¤æ©™è‰²ï¼‰
    """
    # ä»å†…å‚çŸ©é˜µæå–å‚æ•°
    K = intrinsic.intrinsic_matrix
    fx, fy = K[0, 0], K[1, 1]
    cx, cy = K[0, 2], K[1, 2]
    width, height = intrinsic.width, intrinsic.height

    # è®¡ç®—åœ¨ depth = scale å¤„çš„å››ä¸ªè§’ï¼ˆå½’ä¸€åŒ–è®¾å¤‡åæ ‡ï¼‰
    x_right = scale * (width - cx) / fx
    x_left = scale * (0 - cx) / fx
    y_bottom = scale * (height - cy) / fy
    y_top = scale * (0 - cy) / fy

    # ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹ï¼ˆæ·±åº¦ä¸º scaleï¼‰
    corners_cam = np.array([
        [0, 0, 0],           # ç›¸æœºä¸­å¿ƒ
        [x_left, y_top, scale],    # è¿œå¹³é¢å·¦ä¸Š
        [x_right, y_top, scale],   # è¿œå¹³é¢å³ä¸Š
        [x_right, y_bottom, scale],# è¿œå¹³é¢å³ä¸‹
        [x_left, y_bottom, scale]  # è¿œå¹³é¢å·¦ä¸‹
    ])  # (5, 3)

    # è½¬ä¸–ç•Œåæ ‡ï¼šP_world = R @ P_cam + t
    corners_world = (R @ corners_cam.T).T + t  # (5, 3)

    # å®šä¹‰çº¿æ®µ
    lines = [
        [0, 1], [0, 2], [0, 3], [0, 4],  # ä¸­å¿ƒåˆ°å››è§’
        [1, 2], [2, 3], [3, 4], [4, 1]   # åº•éƒ¨çŸ©å½¢
    ]

    # åˆ›å»º LineSet
    frustum = o3d.geometry.LineSet()
    frustum.points = o3d.utility.Vector3dVector(corners_world)
    frustum.lines = o3d.utility.Vector2iVector(lines)
    frustum.colors = o3d.utility.Vector3dVector([color for _ in range(len(lines))])

    return frustum

def main():
    base_dir = '0018cc1438'  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    depth_dir = os.path.join(base_dir, 'depth')
    odometry_file = os.path.join(base_dir, 'odometry.csv')
    rgb_video = os.path.join(base_dir, 'mask.mp4')
    camera_matrix_path = os.path.join(base_dir, 'camera_matrix.csv')
    output_ply = 'results/fused_pointcloud_0018cc1438.ply'

    # -------------------------------
    # ğŸ”§ å‚æ•°è®¾ç½®
    # -------------------------------
    target_size = (256, 192)
    frame_step = 5
    voxel_size = 0.02
    original_rgb_size = (1920, 1440)
    vis_update_freq = 3  # æ¯å‡ å¸§æ›´æ–°ä¸€æ¬¡å¯è§†åŒ–

    # -------------------------------
    # ğŸš€ è®¾å¤‡é€‰æ‹©ï¼šCUDA > CPU
    # -------------------------------
    device = o3c.Device("CUDA:0") if o3c.cuda.is_available() else o3c.Device("CPU:0")
    print(f"Using device: {device}")

    # -------------------------------
    # ğŸš¦ åˆå§‹åŒ–
    # -------------------------------
    print("Loading camera matrix...")
    camera_intrinsics = read_camera_matrix(
        camera_matrix_path,
        target_size=target_size,
        original_size=original_rgb_size
    )

    print("Loading odometry...")
    if not os.path.exists(odometry_file):
        print(f"âŒ Odometry file not found: {odometry_file}")
        return
    odometry_data = read_odometry_csv(odometry_file)

    global_pcd = o3d.t.geometry.PointCloud(device)

    # é¢„ç”Ÿæˆæ·±åº¦æ–‡ä»¶è·¯å¾„
    depth_files = {f: os.path.join(depth_dir, f"{f:06d}.png") for f in odometry_data.keys()}
    available_frames = sorted([
        f for f in odometry_data.keys()
        if os.path.exists(depth_files[f])
    ])
    sampled_frames = available_frames[::frame_step]
    if len(sampled_frames) == 0:
        print("âŒ No valid frames found.")
        return
    print(f"Processing {len(sampled_frames)} frames at {target_size}")

    # -------------------------------
    # ğŸ¥ è§†é¢‘åŠ è½½å™¨
    # -------------------------------
    rgb_loader = RGBVideoLoader(rgb_video, target_size=target_size)

    # -------------------------------
    # âœ… å¯è§†åŒ–è®¾ç½®
    # -------------------------------
    vis = o3d.visualization.Visualizer()
    vis.create_window(window_name="3D Reconstruction + Camera Trajectory", width=1280, height=720)
    render_opt = vis.get_render_option()
    render_opt.point_size = 2
    render_opt.background_color = np.array([0, 0, 0])
    first_update = True
    first_pcd_added = False
    legacy_display_pcd = o3d.geometry.PointCloud()
    frame_times = []

    # âœ… å­˜å‚¨æ‰€æœ‰æœ‰æ•ˆç›¸æœºä½å§¿ï¼ˆç”¨äºæœ€ç»ˆç»˜åˆ¶è½¨è¿¹å’Œè§†é”¥ä½“ï¼‰
    camera_positions = []
    all_frustums = []

    # -------------------------------
    # ğŸ” ä¸»å¾ªç¯
    # -------------------------------
    for i, frame_idx in enumerate(sampled_frames):
        start_time = time.time()

        # åŠ è½½æ•°æ®
        rgb_frame = rgb_loader.get_frame(frame_idx)
        depth_image = get_depth_image(depth_files[frame_idx])

        if rgb_frame is None or depth_image is None:
            print(f"âš ï¸  Missing data for frame {frame_idx}. Skipping.")
            continue

        # å®æ—¶æ˜¾ç¤ºå½“å‰ RGB å¸§
        rgb_frame_rotated = cv2.rotate(rgb_frame, cv2.ROTATE_90_CLOCKWISE)
        display_size = (384, 512)
        rgb_frame_enlarged = cv2.resize(rgb_frame_rotated, display_size, interpolation=cv2.INTER_LINEAR)
        rgb_frame_bgr = cv2.cvtColor(rgb_frame_enlarged, cv2.COLOR_RGB2BGR)
        cv2.imshow("Live RGB", rgb_frame_bgr)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("Real-time video display stopped by user.")
            break

        # ä½å§¿
        data = odometry_data[frame_idx]
        R = quaternion_to_rotation_matrix(data['quaternion'])
        t = data['position']

        # æ·±åº¦è½¬ç‚¹äº‘
        points_camera, valid_mask = depth_to_point_cloud(depth_image, camera_intrinsics)
        if len(points_camera) == 0:
            print(f"âš ï¸  No valid points in depth image for frame {frame_idx}. Skipping.")
            continue

        # è½¬ä¸–ç•Œåæ ‡
        points_world = (R @ points_camera.T).T + t

        # æå–é¢œè‰²
        colors = color_point_cloud(rgb_frame, valid_mask)

        # åˆ›å»º GPU ç‚¹äº‘
        pcd_frame = o3d.t.geometry.PointCloud(device)
        pcd_frame.point["positions"] = o3c.Tensor(points_world.astype(np.float32), device=device)
        pcd_frame.point["colors"] = o3c.Tensor(colors.astype(np.float32), device=device)
        pcd_frame = pcd_frame.voxel_down_sample(voxel_size=voxel_size)

        # ç´¯ç§¯åˆ°å…¨å±€ç‚¹äº‘
        if not first_pcd_added:
            global_pcd = pcd_frame
            first_pcd_added = True
            print("Initialized global point cloud.")
        else:
            global_pcd = global_pcd.voxel_down_sample(voxel_size=voxel_size * 2)
            global_pcd += pcd_frame

        # ğŸ§¹ æ˜¾å­˜/å†…å­˜ä¼˜åŒ–
        del points_camera, points_world, colors, pcd_frame, rgb_frame, depth_image, valid_mask

        # âœ… ä¿å­˜æœ‰æ•ˆä½å§¿ç”¨äºè½¨è¿¹å’Œè§†é”¥ä½“
        camera_positions.append(t.copy())
        frustum = create_camera_frustum(R, t, camera_intrinsics, scale=0.1, color=[1, 0.5, 0])  # æ©™è‰²
        all_frustums.append(frustum)

        # -------------------------------
        # âœ… å¯è§†åŒ–æ›´æ–°ï¼ˆä»…ç‚¹äº‘ï¼‰
        # -------------------------------
        if i % vis_update_freq == 0 or i == len(sampled_frames) - 1:
            num_global_points = len(global_pcd.point["positions"])
            if num_global_points > 50000:
                display_pcd = global_pcd.voxel_down_sample(voxel_size=voxel_size * 1.5)
            else:
                display_pcd = global_pcd

            legacy_display = display_pcd.to_legacy()

            if first_update:
                legacy_display_pcd.points = legacy_display.points
                legacy_display_pcd.colors = legacy_display.colors
                vis.add_geometry(legacy_display_pcd, reset_bounding_box=True)
                first_update = False
            else:
                legacy_display_pcd.points = legacy_display.points
                legacy_display_pcd.colors = legacy_display.colors
                vis.update_geometry(legacy_display_pcd)

        vis.poll_events()
        vis.update_renderer()
        end_time = time.time()
        frame_times.append(end_time - start_time)
        if len(frame_times) > 30:
            frame_times.pop(0)
        avg_fps = len(frame_times) / sum(frame_times) if sum(frame_times) > 0 else 0
        print(f"Frame {frame_idx:6d} | Points: {len(global_pcd.point['positions']):8d} | FPS: {avg_fps:4.1f}")

    # -------------------------------
    # ğŸ§¯ æœ€ç»ˆå¤„ç†
    # -------------------------------
    if len(global_pcd.point["positions"]) == 0:
        print("âŒ No points generated. Exiting.")
        vis.destroy_window()
        cv2.destroyAllWindows()
        rgb_loader.release()
        return

    print(f"\nFinal point cloud has {len(global_pcd.point['positions'])} points. Final down-sampling...")
    global_pcd = global_pcd.voxel_down_sample(voxel_size=voxel_size)
    #save_colmap_compatible_ply(global_pcd, output_ply)

    # -------------------------------
    # âœ… æœ€ç»ˆå¯è§†åŒ–ï¼šæ·»åŠ è½¨è¿¹å’Œæ‰€æœ‰è§†é”¥ä½“
    # -------------------------------
    vis.clear_geometries()

    # æ·»åŠ å…¨å±€ç‚¹äº‘
    legacy_final = global_pcd.to_legacy()
    vis.add_geometry(legacy_final)

    # æ·»åŠ åŸç‚¹åæ ‡ç³»ï¼ˆçº¢-X, ç»¿-Y, è“-Zï¼‰
    global_coord = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])
    vis.add_geometry(global_coord)

    # æ·»åŠ æ‰€æœ‰ç›¸æœºè§†é”¥ä½“
    for frustum in all_frustums:
        vis.add_geometry(frustum, reset_bounding_box=False)

    # æ·»åŠ ç›¸æœºè¿åŠ¨è½¨è¿¹çº¿
    if len(camera_positions) >= 2:
        lines = [[i, i+1] for i in range(len(camera_positions)-1)]
        line_set = o3d.geometry.LineSet()
        line_set.points = o3d.utility.Vector3dVector(camera_positions)
        line_set.lines = o3d.utility.Vector2iVector(lines)
        line_set.colors = o3d.utility.Vector3dVector([[0, 1, 0] for _ in range(len(lines))])  # ç»¿è‰²
        vis.add_geometry(line_set, reset_bounding_box=False)

    vis.reset_view_point(True)
    print(f"\nâœ… Done! Final points: {len(global_pcd.point['positions'])}")
    print("CloseOperation: Close window to exit.")
    vis.run()
    vis.destroy_window()

    # -------------------------------
    # ğŸ§¼ æ¸…ç†èµ„æº
    # -------------------------------
    cv2.destroyAllWindows()
    rgb_loader.release()

if __name__ == "__main__":
    main()